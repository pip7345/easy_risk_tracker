---
sidebar_position: 2
title: Scoring Methodology
---

# ðŸ“‹ Easy Risk Tracker Scoring Methodology

This document outlines the comprehensive methodology used to assess cryptocurrency and Web3 projects. Our framework is designed to provide objective, consistent evaluations across diverse project types.

## Overview

The Easy Risk Tracker uses an **8-category weighted scoring system** that evaluates projects on a 0-10 scale. The final risk score is calculated as a weighted average, with additional consideration for critical red flags that may trigger automatic risk tier upgrades.

---

## Scoring Categories

### 1. Leadership & Team (15% Weight)

Evaluates the credibility, experience, and accountability of project leadership.

| Score | Criteria |
|-------|----------|
| 9-10 | Verified identities, proven track record, industry experience, accessible team |
| 7-8 | Identified team with relevant background, responsive to community |
| 5-6 | Partial team disclosure, limited experience verification |
| 3-4 | Mostly anonymous, concerning past associations |
| 0-2 | Completely anonymous, fake identities, or known bad actors |

**Key Assessment Points:**
- Are team identities verifiable through LinkedIn, public records, or known communities?
- What is their professional background and relevant experience?
- Have they been associated with failed or fraudulent projects?
- Are they accessible and responsive to the community?
- Do they have advisors with credible backgrounds?

---

### 2. Tokenomics (15% Weight)

Analyzes the token's economic structure, distribution, and value capture mechanisms.

| Score | Criteria |
|-------|----------|
| 9-10 | Fair distribution, clear utility, sustainable model, transparent vesting |
| 7-8 | Reasonable allocation, defined utility, standard vesting schedules |
| 5-6 | Some concentration concerns, utility unclear, basic tokenomics |
| 3-4 | High team allocation, minimal utility, pump-and-dump indicators |
| 0-2 | Ponzi-like mechanics, extreme concentration, no real utility |

**Key Assessment Points:**
- Token distribution (team, investors, community, treasury)
- Vesting schedules and lock-up periods
- Token utility within the ecosystem
- Inflation/deflation mechanisms
- Buyback or burn programs

---

### 3. Earning Mechanism (10% Weight)

Evaluates how the project generates revenue and distributes value to participants.

| Score | Criteria |
|-------|----------|
| 9-10 | Clear, sustainable revenue model from real economic activity |
| 7-8 | Defined earning mechanisms with reasonable sustainability |
| 5-6 | Earning model exists but long-term viability uncertain |
| 3-4 | Returns dependent on new participant recruitment |
| 0-2 | Pure Ponzi structure, impossible return promises |

**Key Assessment Points:**
- What is the source of returns/rewards?
- Is the business model sustainable without new investors?
- Are promised returns realistic (compare to market benchmarks)?
- How does value flow through the system?

**ðŸš© Critical Red Flags:**
- Returns exceeding 100% APY without clear source
- Multi-level compensation structures
- Recruitment-based rewards
- "Guaranteed" returns

---

### 4. Liquidity & Market (20% Weight)

The highest-weighted category, assessing the ability to enter and exit positions.

| Score | Criteria |
|-------|----------|
| 9-10 | High volume, multiple major exchanges, tight spreads, price stability |
| 7-8 | Good liquidity on reputable exchanges, reasonable volume |
| 5-6 | Listed but low volume, DEX only, some slippage concerns |
| 3-4 | Very limited liquidity, single exchange, high manipulation risk |
| 0-2 | No market, internal exchange only, withdrawal restrictions |

**Key Assessment Points:**
- Which exchanges list the token?
- Daily/weekly trading volume
- Bid-ask spreads and market depth
- Historical price volatility
- Withdrawal availability and restrictions
- CEX vs DEX availability

---

### 5. Community & Reputation (10% Weight)

Measures authentic community engagement and external perception.

| Score | Criteria |
|-------|----------|
| 9-10 | Large organic community, positive reviews, no major controversies |
| 7-8 | Active community, mostly positive sentiment, minor concerns |
| 5-6 | Moderate engagement, mixed reviews, some bot activity suspected |
| 3-4 | Low engagement, negative reviews prevalent, astroturfing evident |
| 0-2 | Dead community, scam warnings, regulatory notices |

**Key Assessment Points:**
- Social media engagement (authentic vs bots)
- Independent reviews and ratings
- Presence of legal actions or regulatory warnings
- Community growth trends
- Quality of discourse in channels

---

### 6. Technical Quality (15% Weight)

Assesses the technical implementation, security, and innovation of the project.

| Score | Criteria |
|-------|----------|
| 9-10 | Open source, multiple audits, active development, innovative tech |
| 7-8 | Audited code, working product, regular updates |
| 5-6 | Basic product, single audit or none, limited innovation |
| 3-4 | No audit, closed source, technical concerns raised |
| 0-2 | No working product, forked code without attribution, security incidents |

**Key Assessment Points:**
- Has the code been audited? By whom?
- Is the codebase open source?
- GitHub activity and development frequency
- Any past security incidents?
- Technical documentation quality
- Network uptime and reliability

---

### 7. Transparency (10% Weight)

Evaluates openness in operations, finances, and communication.

| Score | Criteria |
|-------|----------|
| 9-10 | Full disclosure, regular reports, proof of reserves, open communication |
| 7-8 | Good documentation, regular updates, responsive support |
| 5-6 | Basic transparency, inconsistent updates, some opacity |
| 3-4 | Limited disclosure, difficult to get information, evasive responses |
| 0-2 | Opaque operations, no financial disclosure, communication blackouts |

**Key Assessment Points:**
- Quality of whitepaper and documentation
- Frequency and quality of updates
- Financial transparency (treasury, spending, revenue)
- Response to community questions
- Corporate structure disclosure
- Legal entity and jurisdiction clarity

---

### 8. Personal Assessment (5% Weight)

A subjective evaluation that captures factors not covered by other categories.

| Score | Criteria |
|-------|----------|
| 9-10 | Would confidently invest/recommend |
| 7-8 | Comfortable with measured participation |
| 5-6 | Cautious interest, significant reservations |
| 3-4 | Would avoid, too many concerns |
| 0-2 | Strong recommendation to avoid |

**Considerations:**
- Gut feeling based on overall analysis
- Risk-reward assessment
- Alignment with investment thesis
- Comparable project benchmarking

---

## Risk Tier Classification

Final scores map to risk tiers with the following thresholds:

| Tier | Score Range | Recommendation |
|------|-------------|----------------|
| ðŸŸ¢ **Low Risk** | 7.5 - 10.0 | Reasonable for consideration with standard due diligence |
| ðŸŸ¡ **Moderate Risk** | 6.0 - 7.4 | Approach with caution, monitor closely, limit exposure |
| ðŸŸ  **High Risk** | 4.0 - 5.9 | Significant concerns, consider avoiding or minimal exposure only |
| ðŸ”´ **Critical Risk** | 0.0 - 3.9 | Severe red flags, strong recommendation to avoid |

### Automatic Critical Risk Triggers

Regardless of numerical score, the following automatically escalate to **ðŸ”´ Critical Risk**:

1. **Legal Actions**: Active lawsuits, regulatory enforcement, or fraud investigations
2. **Confirmed Fraud**: Verified rug pulls, exit scams, or theft
3. **Leadership Issues**: Known scammers, fake identities, or connections to previous frauds
4. **Liquidity Lock**: Inability to withdraw funds without unreasonable conditions
5. **Pyramid Structure**: Compensation primarily from recruitment rather than products/services

---

## Score Calculation

The final score is calculated using weighted averaging:

```
Final Score = (Leadership Ã— 0.15) + (Tokenomics Ã— 0.15) + (Earning Ã— 0.10) + 
              (Liquidity Ã— 0.20) + (Community Ã— 0.10) + (Technical Ã— 0.15) + 
              (Transparency Ã— 0.10) + (Personal Ã— 0.05)
```

### Handling Missing Data

When data is unavailable for a category:

1. **External research** is attempted to gather information
2. If data remains unavailable, the category is marked **N/A**
3. N/A categories are **excluded from calculation** and weights are redistributed proportionally
4. Multiple N/A categories (>3) result in an automatic **Moderate Risk** floor
5. All N/A entries must be **justified** in the project report

---

## Project-Specific Considerations

Different project types may emphasize different criteria:

| Project Type | Key Focus Areas |
|--------------|-----------------|
| **DePIN** | Technical implementation, earning sustainability, token utility |
| **DeFi** | Liquidity, audits, smart contract security |
| **MLM/Investment** | Earning mechanism legitimacy, leadership, regulatory compliance |
| **Stablecoins** | Backing verification, transparency, liquidity |
| **Hardware** | Product quality, company track record, warranty |
| **Education** | Content quality, value delivery, refund policies |

---

## Limitations

This methodology has inherent limitations:

- **Point-in-time**: Assessments reflect information available at assessment date
- **Information asymmetry**: Some projects may have undisclosed information
- **Subjectivity**: Despite structure, some judgment is unavoidable
- **Rapid change**: Crypto markets evolve quickly, requiring regular reassessment
- **Not comprehensive**: Cannot evaluate all possible risk factors

---

## Updates and Revisions

Assessments may be updated when:

- Material new information emerges
- Project fundamentals significantly change
- Regulatory actions occur
- Community feedback provides new verified information
- Periodic scheduled reviews (quarterly)

---

## Version History

| Version | Date | Changes |
|---------|------|---------|
| 1.1 | January 2025 | Added Risk Tier Classification, Improvement Framework, Report Template |
| 1.0 | December 2024 | Initial methodology release |
